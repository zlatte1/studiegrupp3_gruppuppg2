{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf361c36",
   "metadata": {},
   "source": [
    "# Gruppuppgift Del 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b53cd1",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**Name of the person who graded you during \"kamratbedömning\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4370605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "import scipy.special \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c5049",
   "metadata": {},
   "source": [
    "# Chapter 6 in the Book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce77511",
   "metadata": {},
   "source": [
    "## Create two empty vectors, x1 and x2. Now do a for loop 100 times, where you for each iteration: \n",
    "## 1) Take the mean of 100 samples from $N(10, 5)$ and store it in x1. \n",
    "## 2) Take the mean of 100 samples from $N(10, 20)$ and store it in x2.\n",
    "\n",
    "## So, your vectors x1 and x2 should contain 100 values. \n",
    "\n",
    "## From p.148 in the book, we know that the mean is an unbiased estimate of the fixed, but unknown $\\mu$. The nice thing is that in our Monte Carlo Simulation we know the true $\\mu$. Plot histograms of x1 and x2 and comment on the result, do we on \"average\" get the right mean? Is it easier or harder to estimate the mean when the variance is low/high? How is this knowledge useful in reality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137986c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460de478",
   "metadata": {},
   "source": [
    "## Redo the same analysis as above but with 10000 generated samples and see if there is any difference (copy the code from above). Comment on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bde413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2b8e50",
   "metadata": {},
   "source": [
    "# Chapter 7 - Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efa844",
   "metadata": {},
   "source": [
    "Assuming $X$ is $N(10, 3)$, we know (see example calculation below) that a random sample x will with probability 95% be between: <br>\n",
    "ci_lower = 10 - 1.96 x 3 <br> and <br>\n",
    "ci_upper = 10 + 1.96 x 3\n",
    "\n",
    "Example, for the ci_upper, we do the following calculation: $P(X > ci\\_upper) = P(X > 10 + 1.96 * 3) = P(Z > 1.96) = 0.025$ where we used the usual standardization. \n",
    "\n",
    "This means that if you get observations from the normal distribution above, you would \"expect\" 95 \\% of them to be between ci_lower and ci_upper. \n",
    "\n",
    "Your task is now to simulate 10, 100, 1000 and 10000 normally distributed samples from $N(10, 3)$ and check the relative frequency (\\%) of how many samples fall outside the confidence interval. How many \\% should it theoretically be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641568b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12\n",
      "15.879999999999999\n"
     ]
    }
   ],
   "source": [
    "ci_lower = 10 - 1.96*3\n",
    "ci_upper = 10 + 1.96*3\n",
    "\n",
    "print(ci_lower)\n",
    "print(ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"part 1\"\"\"\n",
    "list_10 = np.random.normal(10, 3, size=10)\n",
    "list_100 = np.random.normal(10, 3, size=100)\n",
    "list_1000 = np.random.normal(10, 3, size=1000)\n",
    "list_10000 = np.random.normal(10, 3, size=10000)\n",
    "\n",
    "print(list_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26175b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"testing\"\"\"\n",
    "\n",
    "test_list = np.array([1, 12, 12, 12, 16, 1, 15, 15])\n",
    "\n",
    "#skapar true/false = binomial\n",
    "rel_test_list = np.array((ci_lower < test_list) & (test_list < ci_upper))\n",
    "\n",
    "#samma som ovan + summering av de värden som ligger i utfallet\n",
    "rel_test = np.array(((ci_lower > test_list) + (test_list > ci_upper)).sum())\n",
    "\n",
    "print('som binomial: ', rel_test_list)\n",
    "print()\n",
    "print('antal false = dvs utanför 95% =', rel_test)\n",
    "print()\n",
    "print(type(rel_test)) # var tvungen att vara en array för att ovan skulle fungera.\n",
    "print(len(test_list)) # för att kolla så att \n",
    "\n",
    "print()\n",
    "print('test', (rel_test/len(test_list))*100, '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5519ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"part 2\"\"\"\n",
    "rel_10 = ((ci_lower > list_10) + (list_10 > ci_upper)).sum()\n",
    "rel_100 = ((ci_lower > list_100) + (list_100 > ci_upper)).sum()\n",
    "rel_1000 = ((ci_lower > list_1000) + (list_1000 > ci_upper)).sum()\n",
    "rel_10000 = ((ci_lower > list_10000) + (list_10000 > ci_upper)).sum()\n",
    "\n",
    "print((rel_10/len(list_10))*100, '%')\n",
    "print((rel_100/len(list_100))*100, '%')\n",
    "print((rel_1000/len(list_1000))*100, '%')\n",
    "print((rel_10000/len(list_10000))*100, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894a103",
   "metadata": {},
   "source": [
    "Theoretical should be 5 %\n",
    "\n",
    "\n",
    "\n",
    "google sökningar med resultat som hjälpt till resultatet\n",
    "\n",
    "https://stackoverflow.com/questions/9560207/how-to-count-values-in-a-certain-range-in-a-numpy-array\n",
    "\n",
    "https://www.askpython.com/python/array/array-length-in-python\n",
    "\n",
    "https://www.datacamp.com/tutorial/python-arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644511d1",
   "metadata": {},
   "source": [
    "DEl 2 har bara tagit fram population, ex och standard diviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e37a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_100_b = np.random.normal(10, 3, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ceb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar = np.mean(list_100_b)\n",
    "sigma = np.std(list_100_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar*1,96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7874d4",
   "metadata": {},
   "source": [
    "google sökningar med resultat som hjälpt till resultatet\n",
    "\n",
    "https://www.google.com/search?q=standard+deviation+python&rlz=1C1FKPE_svSE1022SE1022&oq=standard+deviation+py&aqs=chrome.0.0i512j69i57j0i512l4j0i22i30l4.13002j0j7&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf91ab1",
   "metadata": {},
   "source": [
    "## Assume you have 100 observations from N(10, 3), you calculate a confidence interval and check if it \"captures\" the real $\\mu$ (we know the reality since we are doing a monte carlo simulation), how often do you \"capture\" the real mu (in \\%) when you repeat this 1000 times? How is this knowledge useful in reality?\n",
    "\n",
    "## Note, the difference between this question and the one above is that here we calculate the sample mean and sample standard deviation to construct confidence intervals whereas above we used that we \"knew the reality\" ($\\mu$ and $\\sigma$), i.e. ci_lower <- 10 - 1.96*3 and  ci_upper <- 10 + 1.96*3. Obviosuly, this is not the case in reality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28de27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e094ef",
   "metadata": {},
   "source": [
    "## Confidence Intervals for proportions. \n",
    "So far, we have looked at confidence intervals for $\\mu$. Often, we are also interested in proportions, $\\pi$, this is for instance the case in elections that get much attention at TV and \"nyhetsmorgon\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dee8d6",
   "metadata": {},
   "source": [
    "## Assume we ask 1000 people who they will vote for and 4.2% answer Centerpartiet (C). Create a 90% Confidence Interval to get the proportion that would vote for C if we surveyed the whole population (\"Totalundersökning\"). OBS: note we want a 90% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda4b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f039ee",
   "metadata": {},
   "source": [
    "## For this question see (p. 177 - 178) in the book. We ask 1000 people who they will vote for, 4.2% answer Centerpartiet (C) and 4.5% answer Liberalerna (L), is there a statistical significant difference between the two parties? \n",
    "\n",
    "## Check if the assumption on  np(1-p) > 5 is satisfied for both poportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33358ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6d39ad",
   "metadata": {},
   "source": [
    "# Chapter 8 - Hypothesis Testing\n",
    "In the code below, can we reject the hypothesis that $\\mu = 5$ ? Can we reject the hypothesis that $\\mu = 0$ ? How do you interpret the p-value?\n",
    "\n",
    "Read the following documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html to understand the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0293b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scipy.stats.norm.rvs(loc = 0, scale = 4, size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "762425cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=-11.860954973656643, pvalue=1.0179211873506776e-20)\n"
     ]
    }
   ],
   "source": [
    "print(scipy.stats.ttest_1samp(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c1b2c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=-0.29068257828880456, pvalue=0.7719021648598188)\n"
     ]
    }
   ],
   "source": [
    "print(scipy.stats.ttest_1samp(x, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
